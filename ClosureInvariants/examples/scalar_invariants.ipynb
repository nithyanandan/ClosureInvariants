{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as NP\n",
    "\n",
    "from astroutils import nonmathops as NMO\n",
    "\n",
    "from ClosureInvariants import graphUtils as GU\n",
    "# from ClosureInvariants import scalarInvariants as SI\n",
    "from ClosureInvariants import scalarInvariants_torch as SI\n",
    "import torch\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up antennas and array info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_ids = ['O', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "nelements_total = len(element_ids)\n",
    "element_locs = 1e3*NP.random.randn(nelements_total,2) # in lambda units\n",
    "elements_subset = ['O', 'A', 'C', 'E', 'G']\n",
    "elements_remove = ['B', 'D', 'F']\n",
    "nelements_subset = len(elements_subset)\n",
    "element_indices_subset = NMO.find_list_in_list(element_ids, elements_subset)\n",
    "element_locs_subset = element_locs[element_indices_subset,:]\n",
    "print(element_indices_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine antenna pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_pairs = [(element_ids[i], element_ids[j]) for i in range(len(element_ids)) for j in range(i+1,len(element_ids))]\n",
    "npairs = len(element_pairs)\n",
    "element_pairs_locs = NP.array([element_locs[i] - element_locs[j] for i in range(len(element_ids)) for j in range(i+1,len(element_ids))]) # in lambda units\n",
    "element_pairs_subset = [(elements_subset[i], elements_subset[j]) for i in range(len(elements_subset)) for j in range(i+1,len(elements_subset))]\n",
    "npairs_subset = len(element_pairs_subset)\n",
    "element_pairs_indices = [(i,j) for i in range(len(element_ids)) for j in range(i+1,len(element_ids))]\n",
    "element_pairs_subset_indices = [(element_indices_subset[i],element_indices_subset[j]) for i in range(len(elements_subset)) for j in range(i+1,len(elements_subset))]\n",
    "indices_of_subset_pairs = NMO.find_list_in_list(list(map(str,element_pairs)), list(map(str,element_pairs_subset))) # Indices of subset element pairs in all element pairs\n",
    "element_pairs_subset_locs = element_pairs_locs[indices_of_subset_pairs]\n",
    "print(element_pairs)\n",
    "print(element_pairs_indices)\n",
    "print(element_pairs_subset)\n",
    "print(element_pairs_subset_indices)\n",
    "print(indices_of_subset_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the complete and independent set of triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseid = 'O'\n",
    "base_ind = element_ids.index(baseid)\n",
    "base_ind_subset = elements_subset.index(baseid)\n",
    "triads_indep = GU.generate_independent_triads(element_ids, baseid='O')\n",
    "triads_subset_indep = GU.generate_independent_triads(elements_subset, baseid='O')\n",
    "indices_subset_triads = NMO.find_list_in_list(list(map(str,triads_indep)), list(map(str,triads_subset_indep))) # Indices of subset triads in all triads\n",
    "print(triads_indep)\n",
    "print(triads_subset_indep)\n",
    "print(indices_subset_triads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mock cross-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns_shape = (16,12,10) # Shape of number of runs (for example, number of random realisations, timestamps, channels)\n",
    "npol = 1\n",
    "bl_axis = -1 # Baseline axis\n",
    "xc_real_std = 1.0\n",
    "xc_imag_stad = 1.0\n",
    "randseed = None\n",
    "rng = NP.random.default_rng(randseed)\n",
    "xcorr = rng.normal(loc=0.0, scale=xc_real_std, size=nruns_shape+(npairs,)) + 1j * rng.normal(loc=0.0, scale=xc_real_std, size=nruns_shape+(npairs,)) # The last axis is the baseline axis\n",
    "xcorr_subset = NP.take(xcorr, indices_of_subset_pairs, axis=bl_axis) # Take a subset of the baseline axes based on the elements subset\n",
    "xcorr = torch.tensor(xcorr)\n",
    "xcorr_subset = torch.tensor(xcorr_subset)\n",
    "print(xcorr.shape)\n",
    "print(xcorr_subset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up triangular loop correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_lol = SI.corrs_list_on_loops(xcorr, element_pairs, triads_indep, bl_axis=bl_axis) # _lol stands for list of lists\n",
    "corrs_lol_subset_method1 = SI.corrs_list_on_loops(xcorr, element_pairs, triads_subset_indep, bl_axis=bl_axis) # Method 1 from all correlations\n",
    "corrs_lol_subset_method2 = SI.corrs_list_on_loops(xcorr_subset, element_pairs_subset, triads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "print(len(corrs_lol))\n",
    "print(len(corrs_lol_subset_method1))\n",
    "print(len(corrs_lol_subset_method2))\n",
    "# Verify that both methods of setup produce identical results\n",
    "# print(torch.max(torch.tensor([torch.max(i) for i in (NP.abs(NP.array(corrs_lol_subset_method1) - NP.array(corrs_lol_subset_method2)).flatten())])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute advariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advariants = SI.advariants_multiple_loops(corrs_lol)\n",
    "advariants_subset = SI.advariants_multiple_loops(corrs_lol_subset_method1)\n",
    "print(advariants.shape)\n",
    "print(advariants_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the invariants by removing the unknown common scaling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloinv = SI.invariants_from_advariants_method1(advariants, normaxis=-1, normwts=None, normpower=2)\n",
    "cloinv_subset = SI.invariants_from_advariants_method1(advariants_subset, normaxis=-1, normwts=None, normpower=2)\n",
    "print(cloinv.shape)\n",
    "print(cloinv_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the invariance of the closure invariants obtained by corrupting the correlations using element-based gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mock copolar gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_axis = -1 # Antenna axis\n",
    "mean_gain_scale = 3.0 \n",
    "element_gains = rng.normal(loc=1.0, scale=NP.sqrt(0.5)/mean_gain_scale, size=nruns_shape+(nelements_total,)).astype(NP.float64) + 1j * rng.normal(loc=1.0, scale=NP.sqrt(0.5)/mean_gain_scale, size=nruns_shape+(nelements_total,)).astype(NP.float64) # shape is (...,n_element)\n",
    "element_gains_subset = NP.take(element_gains, element_indices_subset, axis=element_axis)\n",
    "print(element_gains.shape)\n",
    "print(element_gains_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupt the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefactor_gains = NP.take(element_gains, NP.array(element_pairs_indices)[:,0], axis=element_axis) # A collection of g_a\n",
    "postfactor_gains = NP.take(element_gains, NP.array(element_pairs_indices)[:,1], axis=element_axis) # A collection of g_b\n",
    "prefactor_gains = torch.tensor(prefactor_gains)\n",
    "postfactor_gains = torch.tensor(postfactor_gains)\n",
    "xcorr_mod = SI.corrupt_visibilities(xcorr, prefactor_gains, postfactor_gains)\n",
    "\n",
    "prefactor_gains_subset = NP.take(element_gains, NP.array(element_pairs_subset_indices)[:,0], axis=element_axis) # A collection of g_a\n",
    "postfactor_gains_subset = NP.take(element_gains, NP.array(element_pairs_subset_indices)[:,1], axis=element_axis) # A collection of g_b\n",
    "prefactor_gains_subset = torch.tensor(prefactor_gains_subset)\n",
    "postfactor_gains_subset = torch.tensor(postfactor_gains_subset)\n",
    "xcorr_subset_mod = SI.corrupt_visibilities(xcorr_subset, prefactor_gains_subset, postfactor_gains_subset)\n",
    "\n",
    "print(xcorr_mod.shape)\n",
    "print(xcorr_subset_mod.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the closure invariants through advariants, and scale factor elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_mod_lol = SI.corrs_list_on_loops(xcorr_mod, element_pairs, triads_indep, bl_axis=bl_axis)\n",
    "corrs_mod_lol_subset_method1 = SI.corrs_list_on_loops(xcorr_mod, element_pairs, triads_subset_indep, bl_axis=bl_axis) # Method 1 from all correlations\n",
    "corrs_mod_lol_subset_method2 = SI.corrs_list_on_loops(xcorr_subset_mod, element_pairs_subset, triads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "print(len(corrs_mod_lol))\n",
    "print(len(corrs_mod_lol_subset_method1))\n",
    "print(len(corrs_mod_lol_subset_method2))\n",
    "# Verify that both methods of setup produce identical results\n",
    "# print(torch.max(torch.tensor([torch.max(i) for i in (NP.abs(NP.array(corrs_lol_subset_method1) - NP.array(corrs_lol_subset_method2)).flatten())])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advariants_mod = SI.advariants_multiple_loops(corrs_mod_lol)\n",
    "advariants_mod_subset = SI.advariants_multiple_loops(corrs_mod_lol_subset_method1)\n",
    "print(advariants_mod.shape)\n",
    "print(advariants_mod_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloinv_mod = SI.invariants_from_advariants_method1(advariants_mod, normaxis=-1, normwts=None, normpower=2)\n",
    "cloinv_mod_subset = SI.invariants_from_advariants_method1(advariants_mod_subset, normaxis=-1, normwts=None, normpower=2)\n",
    "print(cloinv_mod.shape)\n",
    "print(cloinv_mod_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for invariance between ideal and modified versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(cloinv, cloinv_mod))\n",
    "print(NP.allclose(cloinv_subset, cloinv_mod_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify scale factors are as expected, namely absolute squared value of the copolar complex gain of the base vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = NP.abs(element_gains)**2\n",
    "scale_factor_subset = NP.abs(element_gains_subset)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(scale_factor[...,[base_ind]], advariants_mod / advariants))\n",
    "print(NP.allclose(scale_factor_subset[...,[base_ind_subset]], advariants_mod_subset / advariants_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point source verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random point-like object location, intensity, and visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_loc_complex = NP.random.uniform() * NP.exp(1j*NP.random.uniform(low=-NP.pi, high=NP.pi))\n",
    "src_loc = NP.array([src_loc_complex.real, src_loc_complex.imag]).reshape(1,-1) # in (l,m) coordinates\n",
    "src_loc_0 = NP.zeros((1,2), dtype=float) # at origin / phase centre\n",
    "src_amp = NP.random.rand() # in Jy\n",
    "src_vis = NP.sum(src_amp * NP.exp(2j*NP.pi * NP.dot(element_pairs_locs, src_loc.T)), axis=-1)\n",
    "src_vis_subset = src_vis[indices_of_subset_pairs]\n",
    "src_0_vis = NP.sum(src_amp * NP.exp(2j*NP.pi * NP.dot(element_pairs_locs, src_loc_0.T)), axis=-1)\n",
    "src_0_vis_subset = src_0_vis[indices_of_subset_pairs]\n",
    "\n",
    "src_vis = torch.tensor(src_vis)\n",
    "src_vis_subset = torch.tensor(src_vis_subset)\n",
    "src_0_vis = torch.tensor(src_0_vis)\n",
    "src_0_vis_subset = torch.tensor(src_0_vis_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_loc)\n",
    "print(src_loc_0)\n",
    "print(src_vis.shape)\n",
    "print(src_vis_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate advariants for the source visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_corrs_lol = SI.corrs_list_on_loops(src_vis, element_pairs, triads_indep, bl_axis=bl_axis) # _lol stands for list of lists\n",
    "src_corrs_lol_subset_method2 = SI.corrs_list_on_loops(src_vis_subset, element_pairs_subset, triads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "src_advariants = SI.advariants_multiple_loops(src_corrs_lol)\n",
    "src_advariants_subset = SI.advariants_multiple_loops(src_corrs_lol_subset_method2)\n",
    "\n",
    "src_0_corrs_lol = SI.corrs_list_on_loops(src_0_vis, element_pairs, triads_indep, bl_axis=bl_axis) # _lol stands for list of lists\n",
    "src_0_corrs_lol_subset_method2 = SI.corrs_list_on_loops(src_0_vis_subset, element_pairs_subset, triads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "src_0_advariants = SI.advariants_multiple_loops(src_0_corrs_lol)\n",
    "src_0_advariants_subset = SI.advariants_multiple_loops(src_0_corrs_lol_subset_method2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_advariants.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_cloinv_normpow2 = SI.invariants_from_advariants_method1(src_advariants, normaxis=-1, normwts=None, normpower=2)\n",
    "src_cloinv_subset_normpow2 = SI.invariants_from_advariants_method1(src_advariants_subset, normaxis=-1, normwts=None, normpower=2)\n",
    "src_cloinv_normpow1 = SI.invariants_from_advariants_method1(src_advariants, normaxis=-1, normwts=None, normpower=1)\n",
    "src_cloinv_subset_normpow1 = SI.invariants_from_advariants_method1(src_advariants_subset, normaxis=-1, normwts=None, normpower=1)\n",
    "\n",
    "src_0_cloinv_normpow2 = SI.invariants_from_advariants_method1(src_0_advariants, normaxis=-1, normwts=None, normpower=2)\n",
    "src_0_cloinv_subset_normpow2 = SI.invariants_from_advariants_method1(src_0_advariants_subset, normaxis=-1, normwts=None, normpower=2)\n",
    "src_0_cloinv_normpow1 = SI.invariants_from_advariants_method1(src_0_advariants, normaxis=-1, normwts=None, normpower=1)\n",
    "src_0_cloinv_subset_normpow1 = SI.invariants_from_advariants_method1(src_0_advariants_subset, normaxis=-1, normwts=None, normpower=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify invariance to source translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(src_cloinv_normpow2, src_0_cloinv_normpow2))\n",
    "print(NP.allclose(src_cloinv_normpow1, src_0_cloinv_normpow1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify point source closure invariants with \"max\" normalisation of advariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_cloinv_maxnorm_normpow1 = SI.invariants_from_advariants_method1(src_advariants, normaxis=-1, normwts='max', normpower=1)\n",
    "src_cloinv_subset_maxnorm_normpow1 = SI.invariants_from_advariants_method1(src_advariants_subset, normaxis=-1, normwts='max', normpower=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_src_advariant = NP.ones_like(src_advariants)\n",
    "expected_src_cloinv_maxnorm_normpow1 = NP.concatenate([expected_src_advariant.real, expected_src_advariant.imag], axis=-1)\n",
    "\n",
    "expected_src_advariant_subset = NP.ones_like(src_advariants_subset)\n",
    "expected_src_cloinv_subset_maxnorm_normpow1 = NP.concatenate([expected_src_advariant_subset.real, expected_src_advariant_subset.imag], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(src_cloinv_maxnorm_normpow1, expected_src_cloinv_maxnorm_normpow1))\n",
    "print(NP.allclose(src_cloinv_subset_maxnorm_normpow1, expected_src_cloinv_subset_maxnorm_normpow1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify point source closure phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_cphases = SI.closurePhases_from_advariants(src_advariants)\n",
    "print(NP.allclose(src_cphases, NP.zeros(src_advariants.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate independent quads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quads_indep = GU.generate_independent_quads(element_ids)\n",
    "quads_subset_indep = GU.generate_independent_quads(elements_subset)\n",
    "print(len(quads_subset_indep))\n",
    "print(quads_subset_indep)\n",
    "print('----------')\n",
    "print(len(quads_indep))\n",
    "print(quads_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up quadrilateral loop correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_corrs_lol = SI.corrs_list_on_loops(xcorr, element_pairs, quads_indep, bl_axis=bl_axis) # _lol stands for list of lists\n",
    "quad_corrs_lol_subset_method1 = SI.corrs_list_on_loops(xcorr, element_pairs, quads_subset_indep, bl_axis=bl_axis) # Method 1 from all correlations\n",
    "quad_corrs_lol_subset_method2 = SI.corrs_list_on_loops(xcorr_subset, element_pairs_subset, quads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "print(len(quad_corrs_lol))\n",
    "print(len(quad_corrs_lol_subset_method1))\n",
    "print(len(corrs_lol_subset_method2))\n",
    "# Verify that both methods of setup produce identical results\n",
    "# print(torch.max(torch.tensor([torch.max(i) for i in (NP.abs(NP.array(corrs_lol_subset_method1) - NP.array(corrs_lol_subset_method2)).flatten())])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Covariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariants = SI.covariants_multiple_loops(quad_corrs_lol)\n",
    "covariants_subset = SI.covariants_multiple_loops(quad_corrs_lol_subset_method1)\n",
    "print(covariants.shape)\n",
    "print(covariants_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Closure Amplitudes from Covariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clAmp = SI.closureAmplitudes_from_covariants(covariants)\n",
    "clAmp_subset = SI.closureAmplitudes_from_covariants(covariants_subset)\n",
    "print(clAmp.shape)\n",
    "print(clAmp_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute closure amplitudes to gain corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_corrs_mod_lol = SI.corrs_list_on_loops(xcorr_mod, element_pairs, quads_indep, bl_axis=bl_axis)\n",
    "quad_corrs_mod_lol_subset_method1 = SI.corrs_list_on_loops(xcorr_mod, element_pairs, quads_subset_indep, bl_axis=bl_axis) # Method 1 from all correlations\n",
    "quad_corrs_mod_lol_subset_method2 = SI.corrs_list_on_loops(xcorr_subset_mod, element_pairs_subset, quads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "print(len(quad_corrs_mod_lol))\n",
    "print(len(quad_corrs_mod_lol_subset_method1))\n",
    "print(len(quad_corrs_mod_lol_subset_method2))\n",
    "# Verify that both methods of setup produce identical results\n",
    "# print(torch.max(torch.tensor([torch.max(i) for i in (NP.abs(NP.array(corrs_lol_subset_method1) - NP.array(corrs_lol_subset_method2)).flatten())])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariants_mod = SI.covariants_multiple_loops(quad_corrs_mod_lol)\n",
    "covariants_mod_subset = SI.covariants_multiple_loops(quad_corrs_mod_lol_subset_method1)\n",
    "print(covariants_mod.shape)\n",
    "print(covariants_mod_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clAmp_mod = SI.closureAmplitudes_from_covariants(covariants_mod)\n",
    "clAmp_mod_subset = SI.closureAmplitudes_from_covariants(covariants_mod_subset)\n",
    "print(clAmp_mod.shape)\n",
    "print(clAmp_mod_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for invariance between ideal and modified versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(clAmp, clAmp_mod))\n",
    "print(NP.allclose(clAmp_subset, clAmp_mod_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point source verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate covariants for the source visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_quad_corrs_lol = SI.corrs_list_on_loops(src_vis, element_pairs, quads_indep, bl_axis=bl_axis) # _lol stands for list of lists\n",
    "src_quad_corrs_lol_subset_method2 = SI.corrs_list_on_loops(src_vis_subset, element_pairs_subset, quads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "src_covariants = SI.covariants_multiple_loops(src_quad_corrs_lol)\n",
    "src_covariants_subset = SI.covariants_multiple_loops(src_quad_corrs_lol_subset_method2)\n",
    "\n",
    "src_0_quad_corrs_lol = SI.corrs_list_on_loops(src_0_vis, element_pairs, quads_indep, bl_axis=bl_axis) # _lol stands for list of lists\n",
    "src_0_quad_corrs_lol_subset_method2 = SI.corrs_list_on_loops(src_0_vis_subset, element_pairs_subset, quads_subset_indep, bl_axis=bl_axis) # Method 2 from subset correlations\n",
    "src_0_covariants = SI.covariants_multiple_loops(src_0_quad_corrs_lol)\n",
    "src_0_covariants_subset = SI.covariants_multiple_loops(src_0_quad_corrs_lol_subset_method2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify invariance of covariants to source translation. If that is satisfied, closure amplitudes, which are the amplitudes of covariants will also be satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(src_covariants, src_0_covariants))\n",
    "print(NP.allclose(src_covariants_subset, src_0_covariants_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify invariance of closure amplitudes to source translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_clAmp = SI.closureAmplitudes_from_covariants(src_covariants)\n",
    "src_0_clAmp = SI.closureAmplitudes_from_covariants(src_0_covariants)\n",
    "print(NP.allclose(src_clAmp, src_0_clAmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify point source closure amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NP.allclose(src_clAmp, NP.ones(src_covariants.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
